[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)
[![Maintenance](https://img.shields.io/badge/Maintained%3F-YES-green.svg)](https://github.com/RiccardoBiosas/awesome-MLSecOps/graphs/commit-activity)
![GitHub](https://img.shields.io/badge/License-MIT-lightgrey.svg)
[![GitHub](https://img.shields.io/twitter/follow/axsaucedo.svg?label=Follow)](https://twitter.com/RBiosas)
# Awesome MLSecOps

A curated list of awesome open-source tools, resources, and tutorials for MLSecOps (Machine Learning Security Operations).

## Table of Contents

- [Open Source Security Tools](#open-source-security-tools)
- [Attack Vectors](#attack-vectors)
- [Blogs and Publications](#blogs-and-publications)
- [Community Resources](#community-resources)
- [Contributions](#contributions)

## Open Source Security Tools

- [Adversarial Robustness Toolbox](https://github.com/IBM/adversarial-robustness-toolbox) - A library of defense methods for machine learning models against adversarial attacks.
- [MLSploit](https://github.com/mlsploit/) - MLsploit is a cloud framework for interactive experimentation with adversarial machine learning research.
- [TensorFlow Privacy](https://github.com/tensorflow/privacy) - A library of privacy-preserving machine learning algorithms and tools.
- [Foolbox](https://github.com/bethgelab/foolbox) - A Python toolbox for creating and evaluating adversarial attacks and defenses.
- [Advertorch](https://github.com/BorealisAI/advertorch) - A Python toolbox for adversarial robustness research. 
- [Artificial Intelligence Threat Matrix](https://collaborativeaicontrols.github.io/ATM/) - A framework for identifying and mitigating threats to machine learning systems.
- [Adversarial ML Threat Matrix](https://github.com/mitre/advmlthreatmatrix) - Adversarial Threat Landscape for AI Systems.
- [CleverHans](https://github.com/cleverhans-lab/cleverhans) - A library of adversarial examples and defenses for machine learning models.
- [AdvBox](https://github.com/advboxes/AdvBox) - Advbox is a toolbox to generate adversarial examples that fool neural networks in PaddlePaddle、PyTorch、Caffe2、MxNet、Keras、TensorFlow.
- [Audit AI](https://github.com/pymetrics/audit-ai) - Bias Testing for Generalized Machine Learning Applications.
- [Deep Pwning](https://github.com/cchio/deep-pwning) - Deep-pwning is a lightweight framework for experimenting with machine learning models with the goal of evaluating their robustness against a motivated adversary. 
- [Privacy Meter](https://github.com/privacytrustlab/ml_privacy_meter) - An open-source library to audit data privacy in statistical and machine learning algorithms.
- [TensorFlow Model Analysis](https://github.com/tensorflow/model-analysis) - A library for analyzing, validating, and monitoring machine learning models in production.
- [PromptInject](https://github.com/agencyenterprise/PromptInject) - A framework that assembles adversarial prompts


## Attack Vectors

- [Data Poisoning Exploits](https://github.com/ch-shin/awesome-data-poisoning)
- [Adversarial Prompt Exploits](https://research.nccgroup.com/2022/12/05/exploring-prompt-injection-attacks)
- [Evasion Attack](https://blogs.rstudio.com/ai/posts/2020-05-15-model-inversion-attacks/)
- [Membership Inference Exploits](https://arxiv.org/abs/2103.07853)


## Blogs and Publications

- [Token Smuggling Jailbreak via Adversarial Prompt](https://www.piratewires.com/p/gpt4-token-smuggling)
- [Just How Toxic is Data Poisoning? A Unified Benchmark for Backdoor and
Data Poisoning Attacks](https://arxiv.org/pdf/2006.12557.pdf)
- [We need a new way to measure AI security](https://blog.trailofbits.com/2023/03/14/ai-security-safety-audit-assurance-heidy-khlaaf-odd/)
- [PrivacyRaven: Implementing a proof of concept for model inversion](https://blog.trailofbits.com/2021/11/09/privacyraven-implementing-a-proof-of-concept-for-model-inversion/)
- [Adversarial Prompts Engineering](https://github.com/dair-ai/Prompt-Engineering-Guide/blob/main/guides/prompts-adversarial.md)


## Community Resources

- [MLSecOps](https://mlsecops.com/)
- [MLSecOps Podcast](https://open.spotify.com/show/2aPGE0PDVH78JSXTFg378w)


## Contributions
All contributions to this list are welcome!